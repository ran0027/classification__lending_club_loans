{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LendingClub\n",
    "\n",
    "This project develops the machine learning component of a theoretical loan-approval process at LendingClub. The goal of this component is to free up humans to do the tasks that only humans can do, while letting machine learning take care of the rest, allowing for nearly unlimited scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Context\n",
    "\n",
    "I read [this article](https://www.debt.org/credit/loans/personal/lending-club-review/) on how LendingClub loans work to get an idea of how to structure the problem.\n",
    "\n",
    "There are multiple areas of the LendingClub's business model as described above in which machine learning could be useful.\n",
    "\n",
    "However, we are focused strictly on *whether or not to allow a borrower to pass the screening phase*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and wrangling\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accepted_2007_to_2018Q4.csv.gz', 'accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv', 'rejected_2007_to_2018Q4.csv.gz', 'rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv']\n"
     ]
    }
   ],
   "source": [
    "# temporarily unzip arhived data to see names of files within\n",
    "with ZipFile('archive.zip') as zipArchive:\n",
    "    print(zipArchive.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# load data on accepted applications as a Pandas DataFrame\n",
    "with ZipFile('archive.zip') as zipArchive:\n",
    "    with zipArchive.open('accepted_2007_to_2018Q4.csv.gz') as file:\n",
    "        accepted = pd.read_csv(file, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data on rejected applications\n",
    "with ZipFile('archive.zip') as zipArchive:\n",
    "    with zipArchive.open('rejected_2007_to_2018Q4.csv.gz') as file:\n",
    "        rejected = pd.read_csv(file, compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling<img src=\"https://assets.change.org/photos/8/ls/ns/SALsnsqkxAKFuim-1600x900-noPad.jpg?1586140235\" align='right' alt=\"Lasso\" style=\"width: 10%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260701, 151)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many records? How many features?\n",
    "accepted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27648741, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder why there are a different number of features for applications which were rejected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amount Requested', 'Application Date', 'Loan Title', 'Risk_Score',\n",
       "       'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length',\n",
       "       'Policy Code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 9 columns in rejected are also in accepted.\n"
     ]
    }
   ],
   "source": [
    "# check to see if any column names are the same for both dataframes\n",
    "num_cols_in_both = np.sum(accepted.columns.isin([rejected.columns]))\n",
    "print(f'{num_cols_in_both} out of {len(rejected.columns)} columns in rejected are also in accepted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hardship_end_date                              object\n",
       "payment_plan_start_date                        object\n",
       "hardship_length                               float64\n",
       "hardship_dpd                                  float64\n",
       "hardship_loan_status                           object\n",
       "orig_projected_additional_accrued_interest    float64\n",
       "hardship_payoff_balance_amount                float64\n",
       "hardship_last_payment_amount                  float64\n",
       "disbursement_method                            object\n",
       "debt_settlement_flag                           object\n",
       "debt_settlement_flag_date                      object\n",
       "settlement_status                              object\n",
       "settlement_date                                object\n",
       "settlement_amount                             float64\n",
       "settlement_percentage                         float64\n",
       "settlement_term                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at accepted columns, a few at a time\n",
    "accepted.dtypes[135:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to predict whether an applicant should be accepted or rejected, we need a set of features which is common to both types of applicants in our data.\n",
    "\n",
    "Let's see if we can find common features within the two frames, even if they are named differently. Below are the obvious matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        rejected                accepted\n",
    "        \n",
    "        Amount Requested        loan_amnt\n",
    "        \n",
    "        Loan Title              purpose?\n",
    "        \n",
    "        Risk_Score                ???\n",
    "        \n",
    "        Debt-to-Income Ratio      dti\n",
    "        \n",
    "        Zip Code                 zip_code\n",
    "        \n",
    "        State                    addr_state\n",
    "        \n",
    "        Employment Length        emp_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can match up Loan Title with a column in accepted (maybe purpose.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt consolidation                      6418016\n",
       "debt_consolidation                      5895211\n",
       "Other                                   2656222\n",
       "Credit card refinancing                 2298199\n",
       "other                                   2042528\n",
       "                                         ...   \n",
       "dacapo                                        1\n",
       "Consolidation for Good Credit Senior          1\n",
       "Independent Auto Dealer                       1\n",
       "Need money to relocate and buy home           1\n",
       "The Right Way, One More Time                  1\n",
       "Name: Loan Title, Length: 73928, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect examples of Loan Titles\n",
    "rejected['Loan Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_consolidation    1277877\n",
       "credit_card            516971\n",
       "home_improvement       150457\n",
       "other                  139440\n",
       "major_purchase          50445\n",
       "medical                 27488\n",
       "small_business          24689\n",
       "car                     24013\n",
       "vacation                15525\n",
       "moving                  15403\n",
       "house                   14136\n",
       "wedding                  2355\n",
       "renewable_energy         1445\n",
       "educational               424\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect examples of \"purpose\" in accepted df\n",
    "accepted.purpose.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! It appears that Loan Title in rejected is the same / similar information to purpose in accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        rejected                accepted\n",
    "        \n",
    "        Amount Requested        loan_amnt\n",
    "        \n",
    "        Loan Title              purpose\n",
    "        \n",
    "        Risk_Score                ???\n",
    "        \n",
    "        Debt-to-Income Ratio      dti\n",
    "        \n",
    "        Zip Code                 zip_code\n",
    "        \n",
    "        State                    addr_state\n",
    "        \n",
    "        Employment Length        emp_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to match all of the features which seem suitable for prediction, with the exception of risk score. =( There are some scores recorded in the accepted dataframe, but none appear to be LendingClub's \"proprietary risk score\", which I assume is the \"risk score\" in the rejected dataframe.\n",
    "\n",
    "Let me check one more thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    693.0\n",
       "1    703.0\n",
       "2    715.0\n",
       "3    698.0\n",
       "4    509.0\n",
       "5    645.0\n",
       "Name: Risk_Score, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what range are risk scores in?\n",
    "rejected.loc[:5, 'Risk_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675.0</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>715.0</td>\n",
       "      <td>719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>695.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>785.0</td>\n",
       "      <td>789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>690.0</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fico_range_low  fico_range_high\n",
       "0           675.0            679.0\n",
       "1           715.0            719.0\n",
       "2           695.0            699.0\n",
       "3           785.0            789.0\n",
       "4           695.0            699.0\n",
       "5           690.0            694.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what range are fico scores in?\n",
    "accepted.loc[:5, ['fico_range_low', 'fico_range_high']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, it looks like the risk score in the rejected data is NOT proprietary, and probably just a FICO score, so let's match those together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        rejected                accepted\n",
    "        \n",
    "        Amount Requested        loan_amnt\n",
    "        \n",
    "        Loan Title              purpose\n",
    "        \n",
    "        Risk_Score              average of: fico_range_low, fico_range_high\n",
    "        \n",
    "        Debt-to-Income Ratio      dti\n",
    "        \n",
    "        Zip Code                 zip_code\n",
    "        \n",
    "        State                    addr_state\n",
    "        \n",
    "        Employment Length        emp_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to REALLY wrangle this data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
